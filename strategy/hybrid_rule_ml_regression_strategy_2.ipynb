{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Rule-Based Regime + ML Regression Strategy v2\n",
    "\n",
    "## FIXED VERSION - No Data Leakage\n",
    "\n",
    "### Key Fixes:\n",
    "1. **Regression Target A/B Test**:\n",
    "   - Option A: Close-to-Close return (conservative, realistic)\n",
    "   - Option B: VWAP return (volume-weighted average exit)\n",
    "2. **Regime Look-Ahead Fix**: Use previous day's regime (1-day lag)\n",
    "3. **Realistic Execution**: Entry at next bar open with slippage\n",
    "4. **Intra-Bar Stop Loss**: Check if stop hit during holding period\n",
    "\n",
    "### Architecture\n",
    "1. **Rule-Based Regime Detection**: MACD + FD momentum on daily timeframe (1-day lag)\n",
    "2. **ML Regression Models**: Train TWO models (Option A vs Option B)\n",
    "3. **A/B Testing**: Compare both approaches in backtesting\n",
    "4. **Benchmark**: Compare against rule-based and original (leaky) version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import PyCaret for comprehensive regression model comparison\n",
    "from pycaret.regression import *\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Starting Hybrid ML Regression Strategy v2 - FIXED VERSION\")\n",
    "print(\"A/B Testing: Close-to-Close vs VWAP Target\")\n",
    "print(\"Regime: 1-Day Lag (No Look-Ahead Bias)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy configuration\n",
    "CONFIG = {\n",
    "    'stop_loss_pct': 0.04,         # 4% stop loss\n",
    "    'lookforward_hours': 24,       # Look forward 24 hours for target\n",
    "    'commission': 0.0075,          # 0.75% commission per trade\n",
    "    'slippage': 0.0001,            # 0.01% slippage per trade\n",
    "    'regime_timeframe': '1D',      # Daily regime detection\n",
    "    'regime_lag_days': 1,          # Use previous day's regime (FIX)\n",
    "    'train_test_split': 0.70,      # 70% train, 30% test\n",
    "    'min_entry_return': 0.05,      # Minimum predicted return to enter (5%)\n",
    "}\n",
    "\n",
    "print(\"Strategy Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Load 1-minute data\n",
    "df = pd.read_csv('../data/BTCUSD_2023_1min_cleaned.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.set_index('timestamp').sort_index()\n",
    "\n",
    "# Clean unnecessary columns\n",
    "cols_to_drop = [col for col in df.columns if 'Unnamed' in col]\n",
    "df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "print(f\"\\nData loaded: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"Available features: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rule-Based Regime Classification - FIXED (1-Day Lag)\n",
    "\n",
    "**KEY FIX**: Use PREVIOUS day's regime to avoid look-ahead bias\n",
    "\n",
    "- At 2023-10-23 00:00:00, use 2023-10-22's regime classification\n",
    "- Regime calculated from prior day's close, MACD, FD\n",
    "- Realistic for production deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_momentum_regimes_daily_NO_LOOKAHEAD(df_1min, lag_days=1):\n",
    "    \"\"\"\n",
    "    FIXED: Rule-based momentum regime classification on daily timeframe\n",
    "    Uses PREVIOUS day's regime to avoid look-ahead bias\n",
    "    \n",
    "    Args:\n",
    "        lag_days: Number of days to lag regime (default 1 = use yesterday's regime)\n",
    "    \"\"\"\n",
    "    # Aggregate to daily\n",
    "    agg_dict = {\n",
    "        'Open': 'first',\n",
    "        'High': 'max',\n",
    "        'Low': 'min',\n",
    "        'Close': 'last',\n",
    "        'Volume': 'sum'\n",
    "    }\n",
    "    \n",
    "    # Include existing indicators if available\n",
    "    for col in ['macd_12_26', 'macd_sig_12_26', 'macd_hist_12_26', 'rsi_14d', 'fd_14d', 'fd_7d', 'fd_30d']:\n",
    "        if col in df_1min.columns:\n",
    "            agg_dict[col] = 'last'\n",
    "    \n",
    "    df_daily = df_1min.resample('1D').agg(agg_dict).dropna()\n",
    "    \n",
    "    # Calculate daily returns and volatility\n",
    "    df_daily['return'] = df_daily['Close'].pct_change()\n",
    "    df_daily['return_5p'] = df_daily['Close'].pct_change(5)\n",
    "    df_daily['volatility'] = df_daily['return'].rolling(5).std()\n",
    "    \n",
    "    # Initialize regime conditions\n",
    "    bull_condition = pd.Series(False, index=df_daily.index)\n",
    "    bear_condition = pd.Series(False, index=df_daily.index)\n",
    "    \n",
    "    # MACD-based momentum\n",
    "    if 'macd_hist_12_26' in df_daily.columns and 'macd_12_26' in df_daily.columns:\n",
    "        macd_bull = (\n",
    "            (df_daily['macd_12_26'] > df_daily['macd_sig_12_26']) & \n",
    "            (df_daily['macd_hist_12_26'] > 0) &\n",
    "            (df_daily['macd_hist_12_26'] > df_daily['macd_hist_12_26'].shift(1))\n",
    "        )\n",
    "        \n",
    "        macd_bear = (\n",
    "            (df_daily['macd_12_26'] < df_daily['macd_sig_12_26']) & \n",
    "            (df_daily['macd_hist_12_26'] < 0) &\n",
    "            (df_daily['macd_hist_12_26'] < df_daily['macd_hist_12_26'].shift(1))\n",
    "        )\n",
    "        \n",
    "        bull_condition |= macd_bull\n",
    "        bear_condition |= macd_bear\n",
    "    \n",
    "    # Fractal Dimension-based regime\n",
    "    if 'fd_14d' in df_daily.columns:\n",
    "        if 'fd_7d' in df_daily.columns and 'fd_30d' in df_daily.columns:\n",
    "            fd_bull = (df_daily['fd_7d'] > df_daily['fd_30d']) & (df_daily['fd_14d'] > 1.3)\n",
    "            fd_bear = (df_daily['fd_7d'] < df_daily['fd_30d']) & (df_daily['fd_14d'] > 1.5)\n",
    "        else:\n",
    "            fd_ma = df_daily['fd_14d'].rolling(5).mean()\n",
    "            fd_trend = df_daily['fd_14d'] - fd_ma\n",
    "            fd_bull = (fd_trend > 0) & (df_daily['fd_14d'] > df_daily['fd_14d'].rolling(10).quantile(0.6))\n",
    "            fd_bear = df_daily['fd_14d'] > df_daily['fd_14d'].rolling(20).quantile(0.8)\n",
    "        \n",
    "        bull_condition |= fd_bull\n",
    "        bear_condition |= fd_bear\n",
    "    \n",
    "    # Price momentum confirmation\n",
    "    if 'return_5p' in df_daily.columns:\n",
    "        price_bull = df_daily['return_5p'] > df_daily['return_5p'].rolling(10).quantile(0.7)\n",
    "        price_bear = df_daily['return_5p'] < df_daily['return_5p'].rolling(10).quantile(0.3)\n",
    "        \n",
    "        bull_condition &= price_bull\n",
    "        bear_condition &= price_bear\n",
    "    \n",
    "    # Assign regimes: 2=Bull, 1=Sideways, 0=Bear\n",
    "    df_daily['regime'] = np.where(bull_condition, 2, np.where(bear_condition, 0, 1))\n",
    "    \n",
    "    # KEY FIX: SHIFT REGIME BY lag_days\n",
    "    # Today's trading uses YESTERDAY's regime classification\n",
    "    df_daily['regime_lagged'] = df_daily['regime'].shift(lag_days)\n",
    "    \n",
    "    # Map regimes back to 1-minute data using LAGGED regime\n",
    "    df_result = df_1min.copy()\n",
    "    df_result['period'] = df_result.index.floor('D')\n",
    "    \n",
    "    regime_map = dict(zip(df_daily.index, df_daily['regime_lagged']))\n",
    "    df_result['regime'] = df_result['period'].map(regime_map)\n",
    "    df_result['regime'] = df_result['regime'].fillna(method='ffill')\n",
    "    df_result = df_result.drop('period', axis=1)\n",
    "    \n",
    "    return df_result, df_daily\n",
    "\n",
    "# Apply regime classification with lag\n",
    "print(f\"Applying rule-based momentum regime classification...\")\n",
    "print(f\"Regime lag: {CONFIG['regime_lag_days']} day(s) - No look-ahead bias\")\n",
    "print()\n",
    "\n",
    "df_with_regimes, df_daily_regimes = classify_momentum_regimes_daily_NO_LOOKAHEAD(\n",
    "    df, \n",
    "    lag_days=CONFIG['regime_lag_days']\n",
    ")\n",
    "\n",
    "# Show regime distribution\n",
    "regime_names = {0: 'Bear', 1: 'Sideways', 2: 'Bull'}\n",
    "regime_counts = df_with_regimes['regime'].value_counts().sort_index()\n",
    "\n",
    "print(\"\\nRegime Distribution (1-minute data with 1-day lag):\")\n",
    "for regime, count in regime_counts.items():\n",
    "    pct = count / len(df_with_regimes) * 100\n",
    "    print(f\"  {regime_names[regime]:>8} ({regime}): {count:>6,} bars ({pct:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\nDaily regime periods: {len(df_daily_regimes)}\")\n",
    "print(f\"Regime changes: {(df_daily_regimes['regime'].diff() != 0).sum()}\")\n",
    "\n",
    "# Verify lag\n",
    "print(f\"\\nVerifying 1-day lag (first 5 days):\")\n",
    "print(df_daily_regimes[['regime', 'regime_lagged']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Regression Targets - A/B Test\n",
    "\n",
    "### Option A: Close-to-Close Return (Conservative)\n",
    "- Exit at close after 24 hours\n",
    "- Most realistic and executable\n",
    "- Lower variance in targets\n",
    "\n",
    "### Option B: VWAP Return (Volume-Weighted)\n",
    "- Exit at volume-weighted average price\n",
    "- Simulates gradual position exit\n",
    "- More sophisticated than close-to-close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regression_target_CLOSE_TO_CLOSE(df, stop_loss_pct=0.04, lookforward_hours=24):\n",
    "    \"\"\"\n",
    "    OPTION A: Close-to-Close return\n",
    "    \n",
    "    FIXED:\n",
    "    - Exit at close of lookforward window (realistic)\n",
    "    - Check if stop loss hit DURING holding period\n",
    "    - No perfect timing assumption\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    lookforward_bars = lookforward_hours * 60\n",
    "    \n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if i + lookforward_bars >= len(df):\n",
    "            targets.append(np.nan)\n",
    "            continue\n",
    "        \n",
    "        entry_price = df.iloc[i]['Close']\n",
    "        future_window = df.iloc[i+1:i+1+lookforward_bars]\n",
    "        \n",
    "        # Check if stop loss hit DURING holding period\n",
    "        max_loss = (future_window['Low'].min() - entry_price) / entry_price\n",
    "        \n",
    "        if max_loss <= -stop_loss_pct:\n",
    "            # Stop loss hit - exit at stop loss price\n",
    "            gross_return = -stop_loss_pct\n",
    "        else:\n",
    "            # Exit at close of lookforward window (REALISTIC)\n",
    "            exit_price = df.iloc[i + lookforward_bars]['Close']\n",
    "            gross_return = (exit_price - entry_price) / entry_price\n",
    "        \n",
    "        targets.append(gross_return)\n",
    "    \n",
    "    df['target_close'] = targets\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_regression_target_VWAP(df, stop_loss_pct=0.04, lookforward_hours=24):\n",
    "    \"\"\"\n",
    "    OPTION B: VWAP (Volume-Weighted Average Price) return\n",
    "    \n",
    "    FIXED:\n",
    "    - Exit at VWAP over holding period\n",
    "    - More realistic than \"best high\"\n",
    "    - Simulates averaging out of position\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    lookforward_bars = lookforward_hours * 60\n",
    "    \n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if i + lookforward_bars >= len(df):\n",
    "            targets.append(np.nan)\n",
    "            continue\n",
    "        \n",
    "        entry_price = df.iloc[i]['Close']\n",
    "        future_window = df.iloc[i+1:i+1+lookforward_bars]\n",
    "        \n",
    "        # Check if stop loss hit\n",
    "        max_loss = (future_window['Low'].min() - entry_price) / entry_price\n",
    "        \n",
    "        if max_loss <= -stop_loss_pct:\n",
    "            # Stop loss hit\n",
    "            gross_return = -stop_loss_pct\n",
    "        else:\n",
    "            # Exit at VWAP (volume-weighted average)\n",
    "            vwap = (future_window['Close'] * future_window['Volume']).sum() / future_window['Volume'].sum()\n",
    "            gross_return = (vwap - entry_price) / entry_price\n",
    "        \n",
    "        targets.append(gross_return)\n",
    "    \n",
    "    df['target_vwap'] = targets\n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"Creating regression targets - A/B Test...\")\n",
    "print(f\"Lookforward: {CONFIG['lookforward_hours']} hours\")\n",
    "print(f\"Stop loss: {CONFIG['stop_loss_pct']*100:.0f}%\")\n",
    "print()\n",
    "\n",
    "# Create both targets\n",
    "df_with_labels = create_regression_target_CLOSE_TO_CLOSE(\n",
    "    df_with_regimes,\n",
    "    stop_loss_pct=CONFIG['stop_loss_pct'],\n",
    "    lookforward_hours=CONFIG['lookforward_hours']\n",
    ")\n",
    "\n",
    "df_with_labels = create_regression_target_VWAP(\n",
    "    df_with_labels,\n",
    "    stop_loss_pct=CONFIG['stop_loss_pct'],\n",
    "    lookforward_hours=CONFIG['lookforward_hours']\n",
    ")\n",
    "\n",
    "# Compare target distributions\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TARGET COMPARISON: Close-to-Close vs VWAP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for target_col, name in [('target_close', 'Close-to-Close'), ('target_vwap', 'VWAP')]:\n",
    "    valid_targets = df_with_labels[target_col].dropna()\n",
    "    \n",
    "    print(f\"\\n{name} Target Distribution (All Data):\")\n",
    "    print(f\"  Count: {len(valid_targets):,}\")\n",
    "    print(f\"  Mean: {valid_targets.mean():.4f} ({valid_targets.mean()*100:.2f}%)\")\n",
    "    print(f\"  Std: {valid_targets.std():.4f}\")\n",
    "    print(f\"  Min: {valid_targets.min():.4f} ({valid_targets.min()*100:.2f}%)\")\n",
    "    print(f\"  Max: {valid_targets.max():.4f} ({valid_targets.max()*100:.2f}%)\")\n",
    "    print(f\"  Median: {valid_targets.median():.4f} ({valid_targets.median()*100:.2f}%)\")\n",
    "    \n",
    "    # Bull regime only\n",
    "    bull_data = df_with_labels[df_with_labels['regime'] == 2]\n",
    "    bull_targets = bull_data[target_col].dropna()\n",
    "    \n",
    "    print(f\"\\n{name} Target Distribution (Bull Regime Only):\")\n",
    "    print(f\"  Count: {len(bull_targets):,}\")\n",
    "    print(f\"  Mean: {bull_targets.mean():.4f} ({bull_targets.mean()*100:.2f}%)\")\n",
    "    print(f\"  Std: {bull_targets.std():.4f}\")\n",
    "    print(f\"  Positive returns: {(bull_targets > 0).sum():,} ({(bull_targets > 0).sum()/len(bull_targets)*100:.1f}%)\")\n",
    "    print(f\"  Returns > 5%: {(bull_targets > 0.05).sum():,} ({(bull_targets > 0.05).sum()/len(bull_targets)*100:.1f}%)\")\n",
    "    print(f\"  Returns > 10%: {(bull_targets > 0.10).sum():,} ({(bull_targets > 0.10).sum()/len(bull_targets)*100:.1f}%)\")\n",
    "\n",
    "# Compare correlation\n",
    "both_targets = df_with_labels[['target_close', 'target_vwap']].dropna()\n",
    "correlation = both_targets.corr().iloc[0, 1]\n",
    "print(f\"\\nCorrelation between targets: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Features for ML Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature columns (exclude target, regime, and OHLCV)\n",
    "exclude_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'regime', \n",
    "                'target_close', 'target_vwap',\n",
    "                'future_close', 'future_return', 'future_trend']  # Exclude any future-looking features\n",
    "\n",
    "feature_cols = [col for col in df_with_labels.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Available features for ML: {len(feature_cols)}\")\n",
    "print(f\"Features: {feature_cols}\")\n",
    "\n",
    "# Prepare training data (only Bull regime periods)\n",
    "# We'll create separate datasets for each target\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPARING DATASETS FOR A/B TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for target_col, name in [('target_close', 'Close-to-Close'), ('target_vwap', 'VWAP')]:\n",
    "    print(f\"\\n{name} Dataset:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    train_data = df_with_labels[\n",
    "        (df_with_labels['regime'] == 2) &  # Bull regime only\n",
    "        (df_with_labels[target_col].notna())  # Valid labels\n",
    "    ].copy()\n",
    "    \n",
    "    # Remove any rows with NaN in features\n",
    "    train_data_clean = train_data[feature_cols + [target_col]].dropna()\n",
    "    \n",
    "    print(f\"  Training dataset size: {len(train_data_clean):,} samples\")\n",
    "    print(f\"  Target mean: {train_data_clean[target_col].mean():.4f} ({train_data_clean[target_col].mean()*100:.2f}%)\")\n",
    "    print(f\"  Target std: {train_data_clean[target_col].std():.4f}\")\n",
    "    print(f\"  Positive returns: {(train_data_clean[target_col] > 0).sum():,} ({(train_data_clean[target_col] > 0).sum()/len(train_data_clean)*100:.1f}%)\")\n",
    "    print(f\"  Returns > 2%: {(train_data_clean[target_col] > 0.02).sum():,} ({(train_data_clean[target_col] > 0.02).sum()/len(train_data_clean)*100:.1f}%)\")\n",
    "    \n",
    "    # Split into train/test (temporal split)\n",
    "    split_idx = int(len(train_data_clean) * CONFIG['train_test_split'])\n",
    "    train_set = train_data_clean.iloc[:split_idx]\n",
    "    test_set = train_data_clean.iloc[split_idx:]\n",
    "    \n",
    "    X_train = train_set[feature_cols]\n",
    "    y_train = train_set[target_col]\n",
    "    X_test = test_set[feature_cols]\n",
    "    y_test = test_set[target_col]\n",
    "    \n",
    "    print(f\"\\n  Train set: {len(X_train):,} samples\")\n",
    "    print(f\"    Mean target: {y_train.mean():.4f} ({y_train.mean()*100:.2f}%)\")\n",
    "    print(f\"    Positive: {(y_train > 0).sum():,} ({(y_train > 0).sum()/len(y_train)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n  Test set:  {len(X_test):,} samples\")\n",
    "    print(f\"    Mean target: {y_test.mean():.4f} ({y_test.mean()*100:.2f}%)\")\n",
    "    print(f\"    Positive: {(y_test > 0).sum():,} ({(y_test > 0).sum()/len(y_test)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n  Train period: {train_set.index.min()} to {train_set.index.max()}\")\n",
    "    print(f\"  Test period:  {test_set.index.min()} to {test_set.index.max()}\")\n",
    "    \n",
    "    # Store datasets\n",
    "    datasets[name] = {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'train_set': train_set,\n",
    "        'test_set': test_set,\n",
    "        'target_col': target_col\n",
    "    }\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Datasets prepared for A/B testing: {list(datasets.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Selection (Shared Across Both Targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bic_regression(n, mse, num_params):\n",
    "    \"\"\"Calculate BIC for regression model selection\"\"\"\n",
    "    return n * np.log(mse) + num_params * np.log(n)\n",
    "\n",
    "def forward_selection_regression(X, y, max_features=None):\n",
    "    \"\"\"Forward stepwise selection using BIC for regression\"\"\"\n",
    "    n_samples = len(X)\n",
    "    remaining_features = list(X.columns)\n",
    "    selected_features = []\n",
    "    \n",
    "    if max_features is None:\n",
    "        max_features = len(remaining_features)\n",
    "    \n",
    "    best_bic = np.inf\n",
    "    \n",
    "    print(\"Forward Selection Progress (Regression):\")\n",
    "    \n",
    "    for i in range(max_features):\n",
    "        if not remaining_features:\n",
    "            break\n",
    "        \n",
    "        bic_scores = {}\n",
    "        \n",
    "        for feature in remaining_features:\n",
    "            candidate_features = selected_features + [feature]\n",
    "            \n",
    "            # Scale features\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X[candidate_features])\n",
    "            \n",
    "            # Fit regression model\n",
    "            model = Ridge(alpha=1.0, random_state=42)\n",
    "            model.fit(X_scaled, y)\n",
    "            \n",
    "            # Calculate BIC using MSE\n",
    "            y_pred = model.predict(X_scaled)\n",
    "            mse = mean_squared_error(y, y_pred)\n",
    "            bic = calculate_bic_regression(n_samples, mse, len(candidate_features))\n",
    "            bic_scores[feature] = bic\n",
    "        \n",
    "        # Select feature with lowest BIC\n",
    "        best_feature = min(bic_scores, key=bic_scores.get)\n",
    "        best_feature_bic = bic_scores[best_feature]\n",
    "        \n",
    "        # Stop if BIC is not improving\n",
    "        if best_feature_bic >= best_bic:\n",
    "            print(f\"  Stopping: BIC not improving ({best_feature_bic:.2f} >= {best_bic:.2f})\")\n",
    "            break\n",
    "        \n",
    "        # Add feature\n",
    "        selected_features.append(best_feature)\n",
    "        remaining_features.remove(best_feature)\n",
    "        best_bic = best_feature_bic\n",
    "        \n",
    "        if (i + 1) % 5 == 0 or i == 0:\n",
    "            print(f\"  Step {i+1}: Added '{best_feature}', BIC={best_bic:.2f}, Features={len(selected_features)}\")\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "# Use Close-to-Close dataset for feature selection (both should be similar)\n",
    "print(\"\\nStarting feature selection for regression models...\")\n",
    "print(f\"Initial features: {len(feature_cols)}\")\n",
    "print(\"Using Close-to-Close dataset for selection\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_train_ref = datasets['Close-to-Close']['X_train']\n",
    "y_train_ref = datasets['Close-to-Close']['y_train']\n",
    "\n",
    "selected_features = forward_selection_regression(X_train_ref, y_train_ref, max_features=50)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Feature Selection Complete\")\n",
    "print(f\"Selected features: {len(selected_features)} (reduction: {(1 - len(selected_features)/len(feature_cols))*100:.1f}%)\")\n",
    "print(f\"\\nSelected features:\")\n",
    "for i, feat in enumerate(selected_features, 1):\n",
    "    print(f\"  {i:2}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Train Model A: Close-to-Close Target with PyCaret",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Train Model A: Close-to-Close Target with PyCaret"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare data for Option A\nX_train_A = datasets['Close-to-Close']['X_train'][selected_features]\ny_train_A = datasets['Close-to-Close']['y_train']\nX_test_A = datasets['Close-to-Close']['X_test'][selected_features]\ny_test_A = datasets['Close-to-Close']['y_test']\n\ntrain_df_A = X_train_A.copy()\ntrain_df_A['target'] = y_train_A.values\n\ntest_df_A = X_test_A.copy()\ntest_df_A['target'] = y_test_A.values\n\nprint(\"=\"*70)\nprint(\"OPTION A: CLOSE-TO-CLOSE TARGET\")\nprint(\"=\"*70)\nprint(f\"\\nTraining set: {train_df_A.shape}\")\nprint(f\"Test set: {test_df_A.shape}\")\nprint(f\"\\nSetting up PyCaret for Option A...\\n\")\n\n# Setup PyCaret\nsetup_A = setup(\n    data=train_df_A,\n    test_data=test_df_A,\n    target='target',\n    session_id=42,\n    normalize=True,\n    verbose=False,\n    html=False,\n    system_log=False\n)\n\nprint(\"\\nPyCaret setup complete for Option A!\")\nprint(\"\\nComparing regression models...\\n\")\n\n# Compare models\nbest_models_A = compare_models(\n    n_select=10,\n    sort='MAE',\n    turbo=False,\n    errors='ignore'\n)\n\ncomparison_A = pull()\nprint(\"\\n\" + \"=\"*70)\nprint(\"OPTION A: TOP 10 MODELS\")\nprint(\"=\"*70)\nprint(comparison_A.head(10).to_string())\n\n# Select best model\nbest_model_A = best_models_A[0]\nbest_model_name_A = type(best_model_A).__name__\n\nprint(f\"\\n{'='*70}\")\nprint(f\"OPTION A BEST MODEL: {best_model_name_A}\")\nprint(\"=\"*70)\n\n# Evaluate on test set\ntest_pred_A = predict_model(best_model_A, data=test_df_A)\ny_test_actual_A = test_pred_A['target'].values\ny_test_pred_A = test_pred_A['prediction_label'].values\n\ntest_r2_A = r2_score(y_test_actual_A, y_test_pred_A)\ntest_mae_A = mean_absolute_error(y_test_actual_A, y_test_pred_A)\n\nprint(f\"\\nTest Metrics:\")\nprint(f\"  MAE: {test_mae_A:.4f} ({test_mae_A*100:.2f}%)\")\nprint(f\"  R\u00b2:  {test_r2_A:.4f}\")\nprint(f\"\\nPrediction Distribution:\")\nprint(f\"  Mean: {y_test_pred_A.mean():.4f} ({y_test_pred_A.mean()*100:.2f}%)\")\nprint(f\"  Min:  {y_test_pred_A.min():.4f} ({y_test_pred_A.min()*100:.2f}%)\")\nprint(f\"  Max:  {y_test_pred_A.max():.4f} ({y_test_pred_A.max()*100:.2f}%)\")\nprint(f\"  Predictions > 5%: {(y_test_pred_A > 0.05).sum()} ({(y_test_pred_A > 0.05).sum()/len(y_test_pred_A)*100:.1f}%)\")\n\n# Finalize model\nmodel_A_final = finalize_model(best_model_A)\nprint(f\"\\nModel A finalized for backtesting!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Train Model B: VWAP Target with PyCaret"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare data for Option B\nX_train_B = datasets['VWAP']['X_train'][selected_features]\ny_train_B = datasets['VWAP']['y_train']\nX_test_B = datasets['VWAP']['X_test'][selected_features]\ny_test_B = datasets['VWAP']['y_test']\n\ntrain_df_B = X_train_B.copy()\ntrain_df_B['target'] = y_train_B.values\n\ntest_df_B = X_test_B.copy()\ntest_df_B['target'] = y_test_B.values\n\nprint(\"=\"*70)\nprint(\"OPTION B: VWAP TARGET\")\nprint(\"=\"*70)\nprint(f\"\\nTraining set: {train_df_B.shape}\")\nprint(f\"Test set: {test_df_B.shape}\")\nprint(f\"\\nSetting up PyCaret for Option B...\\n\")\n\n# Setup PyCaret\nsetup_B = setup(\n    data=train_df_B,\n    test_data=test_df_B,\n    target='target',\n    session_id=42,\n    normalize=True,\n    verbose=False,\n    html=False,\n    system_log=False\n)\n\nprint(\"\\nPyCaret setup complete for Option B!\")\nprint(\"\\nComparing regression models...\\n\")\n\n# Compare models\nbest_models_B = compare_models(\n    n_select=10,\n    sort='MAE',\n    turbo=False,\n    errors='ignore'\n)\n\ncomparison_B = pull()\nprint(\"\\n\" + \"=\"*70)\nprint(\"OPTION B: TOP 10 MODELS\")\nprint(\"=\"*70)\nprint(comparison_B.head(10).to_string())\n\n# Select best model\nbest_model_B = best_models_B[0]\nbest_model_name_B = type(best_model_B).__name__\n\nprint(f\"\\n{'='*70}\")\nprint(f\"OPTION B BEST MODEL: {best_model_name_B}\")\nprint(\"=\"*70)\n\n# Evaluate on test set\ntest_pred_B = predict_model(best_model_B, data=test_df_B)\ny_test_actual_B = test_pred_B['target'].values\ny_test_pred_B = test_pred_B['prediction_label'].values\n\ntest_r2_B = r2_score(y_test_actual_B, y_test_pred_B)\ntest_mae_B = mean_absolute_error(y_test_actual_B, y_test_pred_B)\n\nprint(f\"\\nTest Metrics:\")\nprint(f\"  MAE: {test_mae_B:.4f} ({test_mae_B*100:.2f}%)\")\nprint(f\"  R\u00b2:  {test_r2_B:.4f}\")\nprint(f\"\\nPrediction Distribution:\")\nprint(f\"  Mean: {y_test_pred_B.mean():.4f} ({y_test_pred_B.mean()*100:.2f}%)\")\nprint(f\"  Min:  {y_test_pred_B.min():.4f} ({y_test_pred_B.min()*100:.2f}%)\")\nprint(f\"  Max:  {y_test_pred_B.max():.4f} ({y_test_pred_B.max()*100:.2f}%)\")\nprint(f\"  Predictions > 5%: {(y_test_pred_B > 0.05).sum()} ({(y_test_pred_B > 0.05).sum()/len(y_test_pred_B)*100:.1f}%)\")\n\n# Finalize model\nmodel_B_final = finalize_model(best_model_B)\nprint(f\"\\nModel B finalized for backtesting!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Backtesting Framework - FIXED (Realistic Execution)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class FeeAwareExitManager:\n    \"\"\"Exit logic with transaction fees\"\"\"\n    \n    def __init__(self, commission=0.0075, slippage=0.0001):\n        self.commission = commission\n        self.slippage = slippage\n        self.total_cost = commission + slippage\n        self.round_trip_cost = self.total_cost * 2\n        \n        print(f\"Fee-Aware Exit Manager:\")\n        print(f\"  Commission: {commission*100:.2f}%\")\n        print(f\"  Slippage: {slippage*100:.3f}%\")\n        print(f\"  Round-trip cost: {self.round_trip_cost*100:.2f}%\")\n    \n    def calculate_net_pnl(self, entry_price, exit_price):\n        \"\"\"Calculate P&L after fees\"\"\"\n        gross_return = (exit_price - entry_price) / entry_price\n        net_return = gross_return - self.round_trip_cost\n        return net_return\n    \n    def should_exit(self, entry_price, current_price, entry_regime, current_regime, stop_loss_pct=0.04):\n        \"\"\"Determine if position should be exited\"\"\"\n        net_pnl = self.calculate_net_pnl(entry_price, current_price)\n        \n        # Rule 1: Stop loss\n        if net_pnl <= -stop_loss_pct:\n            return True, f\"Stop loss: {net_pnl:.2%}\"\n        \n        # Rule 2: Regime change\n        if current_regime != entry_regime:\n            return True, f\"Regime change: {entry_regime}->{current_regime}, P&L: {net_pnl:.2%}\"\n        \n        return False, f\"Hold (P&L: {net_pnl:.2%})\"\n\nfee_manager = FeeAwareExitManager(\n    commission=CONFIG['commission'],\n    slippage=CONFIG['slippage']\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def backtest_hybrid_regression_FIXED(df, ml_model, selected_features, fee_manager, \n                                     stop_loss=0.04, min_return=0.05, model_name=\"Model\"):\n    \"\"\"\n    FIXED: Backtest with realistic execution\n    - Entry at NEXT bar open (after prediction)\n    - Entry slippage applied\n    - No look-ahead bias\n    \"\"\"\n    capital = 10000\n    position = None\n    trades = []\n    equity_curve = []\n    ml_predictions_log = []\n    \n    for i in range(len(df) - 1):  # -1 because we need next bar for entry\n        row = df.iloc[i]\n        timestamp = row.name\n        price = row['Close']\n        regime = row['regime']\n        \n        # Check exit conditions if in position\n        if position is not None:\n            should_exit, exit_reason = fee_manager.should_exit(\n                position['entry_price'],\n                price,\n                position['entry_regime'],\n                regime,\n                stop_loss\n            )\n            \n            if should_exit:\n                # Exit at current close with slippage\n                exit_price = price * (1 - fee_manager.slippage)\n                exit_return = fee_manager.calculate_net_pnl(position['entry_price'], exit_price)\n                capital *= (1 + exit_return)\n                \n                trades.append({\n                    'entry_time': position['entry_time'],\n                    'exit_time': timestamp,\n                    'entry_price': position['entry_price'],\n                    'exit_price': exit_price,\n                    'return_pct': exit_return * 100,\n                    'exit_reason': exit_reason,\n                    'regime': position['entry_regime'],\n                    'predicted_return': position.get('predicted_return', None)\n                })\n                \n                position = None\n        \n        # Check entry conditions if not in position\n        if position is None and regime == 2:  # Bull regime only\n            try:\n                features_df = pd.DataFrame([row[selected_features].values], columns=selected_features)\n                \n                if not features_df.isnull().any().any():\n                    # Get prediction using PyCaret\n                    pred_df = predict_model(ml_model, data=features_df)\n                    predicted_return = pred_df['prediction_label'].iloc[0]\n                    \n                    ml_predictions_log.append({'timestamp': timestamp, 'predicted_return': predicted_return})\n                    \n                    # FIX: Enter if prediction exceeds threshold\n                    if predicted_return >= min_return:\n                        # FIX: Enter at NEXT bar open with slippage\n                        next_bar = df.iloc[i + 1]\n                        entry_price = next_bar['Open'] * (1 + fee_manager.slippage)\n                        entry_timestamp = next_bar.name\n                        \n                        position = {\n                            'entry_time': entry_timestamp,\n                            'entry_price': entry_price,\n                            'entry_regime': regime,\n                            'predicted_return': predicted_return\n                        }\n            except:\n                pass\n        \n        equity_curve.append(capital)\n    \n    # Close any open position at end\n    if position is not None:\n        final_price = df.iloc[-1]['Close'] * (1 - fee_manager.slippage)\n        exit_return = fee_manager.calculate_net_pnl(position['entry_price'], final_price)\n        capital *= (1 + exit_return)\n        \n        trades.append({\n            'entry_time': position['entry_time'],\n            'exit_time': df.index[-1],\n            'entry_price': position['entry_price'],\n            'exit_price': final_price,\n            'return_pct': exit_return * 100,\n            'exit_reason': 'End of backtest',\n            'regime': position['entry_regime'],\n            'predicted_return': position.get('predicted_return', None)\n        })\n    \n    equity_curve.append(capital)\n    \n    return {\n        'model_name': model_name,\n        'final_capital': capital,\n        'total_return': (capital - 10000) / 10000 * 100,\n        'trades': trades,\n        'equity_curve': equity_curve,\n        'num_trades': len(trades),\n        'ml_predictions': ml_predictions_log\n    }\n\ndef backtest_rule_based_bull(df, fee_manager, stop_loss=0.04):\n    \"\"\"Rule-based Bull regime benchmark strategy\"\"\"\n    capital = 10000\n    position = None\n    trades = []\n    equity_curve = []\n    \n    for i in range(len(df)):\n        row = df.iloc[i]\n        timestamp = row.name\n        price = row['Close']\n        regime = row['regime']\n        \n        if position is not None:\n            should_exit, exit_reason = fee_manager.should_exit(\n                position['entry_price'],\n                price,\n                position['entry_regime'],\n                regime,\n                stop_loss\n            )\n            \n            if should_exit:\n                exit_price = price * (1 - fee_manager.slippage)\n                exit_return = fee_manager.calculate_net_pnl(position['entry_price'], exit_price)\n                capital *= (1 + exit_return)\n                \n                trades.append({\n                    'entry_time': position['entry_time'],\n                    'exit_time': timestamp,\n                    'entry_price': position['entry_price'],\n                    'exit_price': exit_price,\n                    'return_pct': exit_return * 100,\n                    'exit_reason': exit_reason,\n                    'regime': position['entry_regime']\n                })\n                \n                position = None\n        \n        if position is None and regime == 2:\n            if i == 0 or df.iloc[i-1]['regime'] != 2:\n                entry_price = price * (1 + fee_manager.slippage)\n                position = {\n                    'entry_time': timestamp,\n                    'entry_price': entry_price,\n                    'entry_regime': regime\n                }\n        \n        equity_curve.append(capital)\n    \n    if position is not None:\n        final_price = df.iloc[-1]['Close'] * (1 - fee_manager.slippage)\n        exit_return = fee_manager.calculate_net_pnl(position['entry_price'], final_price)\n        capital *= (1 + exit_return)\n        \n        trades.append({\n            'entry_time': position['entry_time'],\n            'exit_time': df.index[-1],\n            'entry_price': position['entry_price'],\n            'exit_price': final_price,\n            'return_pct': exit_return * 100,\n            'exit_reason': 'End of backtest',\n            'regime': position['entry_regime']\n        })\n    \n    return {\n        'model_name': 'Rule-Based Bull',\n        'final_capital': capital,\n        'total_return': (capital - 10000) / 10000 * 100,\n        'trades': trades,\n        'equity_curve': equity_curve,\n        'num_trades': len(trades)\n    }\n\nprint(\"Backtesting strategies defined with FIXED realistic execution\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Run Backtests - A/B Comparison"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare backtest data (test period)\ntest_start = datasets['Close-to-Close']['test_set'].index.min()\ntest_end = datasets['Close-to-Close']['test_set'].index.max()\ndf_backtest = df_with_labels.loc[test_start:test_end].copy()\n\nprint(\"=\"*70)\nprint(\"RUNNING BACKTESTS - A/B COMPARISON\")\nprint(\"=\"*70)\nprint(f\"\\nBacktest period: {test_start} to {test_end}\")\nprint(f\"Total bars: {len(df_backtest):,}\")\nprint(f\"Bull regime bars: {(df_backtest['regime'] == 2).sum():,}\")\nprint(f\"Minimum Entry Return: {CONFIG['min_entry_return']*100:.0f}%\")\nprint(f\"Stop Loss: {CONFIG['stop_loss_pct']*100:.0f}%\")\n\n# Backtest Option A\nprint(\"\\n\" + \"=\"*70)\nprint(\"BACKTEST: OPTION A (Close-to-Close Model)\")\nprint(\"=\"*70)\n\nresults_A = backtest_hybrid_regression_FIXED(\n    df_backtest,\n    model_A_final,\n    selected_features,\n    fee_manager,\n    stop_loss=CONFIG['stop_loss_pct'],\n    min_return=CONFIG['min_entry_return'],\n    model_name=f\"Option A ({best_model_name_A})\"\n)\n\nprint(f\"\\nResults:\")\nprint(f\"  Final Capital: ${results_A['final_capital']:.2f}\")\nprint(f\"  Total Return: {results_A['total_return']:.2f}%\")\nprint(f\"  Number of Trades: {results_A['num_trades']}\")\n\nif results_A['num_trades'] > 0:\n    trades_A = pd.DataFrame(results_A['trades'])\n    winners_A = trades_A[trades_A['return_pct'] > 0]\n    losers_A = trades_A[trades_A['return_pct'] <= 0]\n    \n    print(f\"\\n  Trade Performance:\")\n    print(f\"    Winners: {len(winners_A)} ({len(winners_A)/len(trades_A)*100:.1f}%)\")\n    print(f\"    Losers: {len(losers_A)} ({len(losers_A)/len(trades_A)*100:.1f}%)\")\n    if len(winners_A) > 0:\n        print(f\"    Avg Win: {winners_A['return_pct'].mean():.2f}%\")\n    if len(losers_A) > 0:\n        print(f\"    Avg Loss: {losers_A['return_pct'].mean():.2f}%\")\n    print(f\"    Best: {trades_A['return_pct'].max():.2f}%\")\n    print(f\"    Worst: {trades_A['return_pct'].min():.2f}%\")\n\n# Backtest Option B\nprint(\"\\n\" + \"=\"*70)\nprint(\"BACKTEST: OPTION B (VWAP Model)\")\nprint(\"=\"*70)\n\nresults_B = backtest_hybrid_regression_FIXED(\n    df_backtest,\n    model_B_final,\n    selected_features,\n    fee_manager,\n    stop_loss=CONFIG['stop_loss_pct'],\n    min_return=CONFIG['min_entry_return'],\n    model_name=f\"Option B ({best_model_name_B})\"\n)\n\nprint(f\"\\nResults:\")\nprint(f\"  Final Capital: ${results_B['final_capital']:.2f}\")\nprint(f\"  Total Return: {results_B['total_return']:.2f}%\")\nprint(f\"  Number of Trades: {results_B['num_trades']}\")\n\nif results_B['num_trades'] > 0:\n    trades_B = pd.DataFrame(results_B['trades'])\n    winners_B = trades_B[trades_B['return_pct'] > 0]\n    losers_B = trades_B[trades_B['return_pct'] <= 0]\n    \n    print(f\"\\n  Trade Performance:\")\n    print(f\"    Winners: {len(winners_B)} ({len(winners_B)/len(trades_B)*100:.1f}%)\")\n    print(f\"    Losers: {len(losers_B)} ({len(losers_B)/len(trades_B)*100:.1f}%)\")\n    if len(winners_B) > 0:\n        print(f\"    Avg Win: {winners_B['return_pct'].mean():.2f}%\")\n    if len(losers_B) > 0:\n        print(f\"    Avg Loss: {losers_B['return_pct'].mean():.2f}%\")\n    print(f\"    Best: {trades_B['return_pct'].max():.2f}%\")\n    print(f\"    Worst: {trades_B['return_pct'].min():.2f}%\")\n\n# Backtest Benchmark\nprint(\"\\n\" + \"=\"*70)\nprint(\"BACKTEST: BENCHMARK (Rule-Based Bull)\")\nprint(\"=\"*70)\n\nresults_benchmark = backtest_rule_based_bull(\n    df_backtest,\n    fee_manager,\n    stop_loss=CONFIG['stop_loss_pct']\n)\n\nprint(f\"\\nResults:\")\nprint(f\"  Final Capital: ${results_benchmark['final_capital']:.2f}\")\nprint(f\"  Total Return: {results_benchmark['total_return']:.2f}%\")\nprint(f\"  Number of Trades: {results_benchmark['num_trades']}\")\n\nif results_benchmark['num_trades'] > 0:\n    trades_bench = pd.DataFrame(results_benchmark['trades'])\n    winners_bench = trades_bench[trades_bench['return_pct'] > 0]\n    losers_bench = trades_bench[trades_bench['return_pct'] <= 0]\n    \n    print(f\"\\n  Trade Performance:\")\n    print(f\"    Winners: {len(winners_bench)} ({len(winners_bench)/len(trades_bench)*100:.1f}%)\")\n    print(f\"    Losers: {len(losers_bench)} ({len(losers_bench)/len(trades_bench)*100:.1f}%)\")\n    if len(winners_bench) > 0:\n        print(f\"    Avg Win: {winners_bench['return_pct'].mean():.2f}%\")\n    if len(losers_bench) > 0:\n        print(f\"    Avg Loss: {losers_bench['return_pct'].mean():.2f}%\")\n    print(f\"    Best: {trades_bench['return_pct'].max():.2f}%\")\n    print(f\"    Worst: {trades_bench['return_pct'].min():.2f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Final Comparison and Visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create comprehensive comparison\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL A/B TEST COMPARISON\")\nprint(\"=\"*70)\n\ncomparison_df = pd.DataFrame({\n    'Strategy': [\n        f'Option A: Close-to-Close ({best_model_name_A})',\n        f'Option B: VWAP ({best_model_name_B})',\n        'Benchmark: Rule-Based Bull'\n    ],\n    'Final Capital': [\n        results_A['final_capital'],\n        results_B['final_capital'],\n        results_benchmark['final_capital']\n    ],\n    'Total Return (%)': [\n        results_A['total_return'],\n        results_B['total_return'],\n        results_benchmark['total_return']\n    ],\n    'Num Trades': [\n        results_A['num_trades'],\n        results_B['num_trades'],\n        results_benchmark['num_trades']\n    ]\n})\n\n# Add win rates\nfor idx, results in enumerate([results_A, results_B, results_benchmark]):\n    if results['num_trades'] > 0:\n        trades_df = pd.DataFrame(results['trades'])\n        win_rate = (trades_df['return_pct'] > 0).sum() / len(trades_df) * 100\n        avg_return = trades_df['return_pct'].mean()\n        comparison_df.loc[idx, 'Win Rate (%)'] = win_rate\n        comparison_df.loc[idx, 'Avg Return per Trade (%)'] = avg_return\n    else:\n        comparison_df.loc[idx, 'Win Rate (%)'] = 0\n        comparison_df.loc[idx, 'Avg Return per Trade (%)'] = 0\n\nprint(\"\\n\" + comparison_df.to_string(index=False))\n\n# Determine winner\nbest_return = comparison_df['Total Return (%)'].max()\nwinner_idx = comparison_df['Total Return (%)'].idxmax()\nwinner_name = comparison_df.loc[winner_idx, 'Strategy']\n\nprint(f\"\\n\" + \"=\"*70)\nprint(f\"WINNER: {winner_name}\")\nprint(f\"Return: {best_return:.2f}%\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Comprehensive visualization\nfig, axes = plt.subplots(3, 1, figsize=(20, 18))\n\n# Resample to hourly\ndf_hourly = df_backtest.resample('1H').agg({\n    'Open': 'first',\n    'High': 'max',\n    'Low': 'min',\n    'Close': 'last',\n    'regime': 'last'\n}).dropna()\n\nregime_colors = {0: 'lightcoral', 1: 'lightgray', 2: 'lightgreen'}\nregime_names = {0: 'Bear', 1: 'Sideways', 2: 'Bull'}\n\n# Plot 1: Option A\nax1 = axes[0]\nax1.plot(df_hourly.index, df_hourly['Close'], label='BTC Price', color='black', linewidth=1.5, alpha=0.8)\n\nfor regime_val in [0, 1, 2]:\n    regime_mask = df_hourly['regime'] == regime_val\n    if regime_mask.any():\n        ax1.fill_between(df_hourly.index, \n                         df_hourly['Close'].min() * 0.95, \n                         df_hourly['Close'].max() * 1.05,\n                         where=regime_mask,\n                         alpha=0.2,\n                         color=regime_colors[regime_val],\n                         label=f'{regime_names[regime_val]} Regime')\n\nif results_A['num_trades'] > 0:\n    for _, trade in pd.DataFrame(results_A['trades']).iterrows():\n        color = 'blue' if trade['return_pct'] > 0 else 'red'\n        ax1.scatter(trade['entry_time'], trade['entry_price'], color='green', marker='^', s=200, zorder=5,\n                   edgecolors='darkgreen', linewidths=2)\n        ax1.scatter(trade['exit_time'], trade['exit_price'], color=color, marker='v', s=200, zorder=5,\n                   edgecolors='darkblue' if color == 'blue' else 'darkred', linewidths=2)\n        ax1.plot([trade['entry_time'], trade['exit_time']], [trade['entry_price'], trade['exit_price']],\n                color=color, linestyle='--', linewidth=2, alpha=0.6)\n        mid_time = trade['entry_time'] + (trade['exit_time'] - trade['entry_time']) / 2\n        mid_price = (trade['entry_price'] + trade['exit_price']) / 2\n        ax1.annotate(f\"{trade['return_pct']:.1f}%\", xy=(mid_time, mid_price),\n                    fontsize=10, fontweight='bold',\n                    bbox=dict(boxstyle='round,pad=0.3', facecolor=color, alpha=0.3))\n\nax1.set_title(f'Option A: Close-to-Close ({best_model_name_A}) - {results_A[\"total_return\"]:.2f}% Return', \n              fontsize=14, fontweight='bold')\nax1.set_ylabel('BTC Price (USD)', fontsize=12)\nax1.legend(loc='upper left', fontsize=9)\nax1.grid(True, alpha=0.3)\n\n# Plot 2: Option B\nax2 = axes[1]\nax2.plot(df_hourly.index, df_hourly['Close'], label='BTC Price', color='black', linewidth=1.5, alpha=0.8)\n\nfor regime_val in [0, 1, 2]:\n    regime_mask = df_hourly['regime'] == regime_val\n    if regime_mask.any():\n        ax2.fill_between(df_hourly.index, \n                         df_hourly['Close'].min() * 0.95, \n                         df_hourly['Close'].max() * 1.05,\n                         where=regime_mask,\n                         alpha=0.2,\n                         color=regime_colors[regime_val],\n                         label=f'{regime_names[regime_val]} Regime')\n\nif results_B['num_trades'] > 0:\n    for _, trade in pd.DataFrame(results_B['trades']).iterrows():\n        color = 'blue' if trade['return_pct'] > 0 else 'red'\n        ax2.scatter(trade['entry_time'], trade['entry_price'], color='green', marker='^', s=200, zorder=5,\n                   edgecolors='darkgreen', linewidths=2)\n        ax2.scatter(trade['exit_time'], trade['exit_price'], color=color, marker='v', s=200, zorder=5,\n                   edgecolors='darkblue' if color == 'blue' else 'darkred', linewidths=2)\n        ax2.plot([trade['entry_time'], trade['exit_time']], [trade['entry_price'], trade['exit_price']],\n                color=color, linestyle='--', linewidth=2, alpha=0.6)\n        mid_time = trade['entry_time'] + (trade['exit_time'] - trade['entry_time']) / 2\n        mid_price = (trade['entry_price'] + trade['exit_price']) / 2\n        ax2.annotate(f\"{trade['return_pct']:.1f}%\", xy=(mid_time, mid_price),\n                    fontsize=10, fontweight='bold',\n                    bbox=dict(boxstyle='round,pad=0.3', facecolor=color, alpha=0.3))\n\nax2.set_title(f'Option B: VWAP ({best_model_name_B}) - {results_B[\"total_return\"]:.2f}% Return', \n              fontsize=14, fontweight='bold')\nax2.set_ylabel('BTC Price (USD)', fontsize=12)\nax2.legend(loc='upper left', fontsize=9)\nax2.grid(True, alpha=0.3)\n\n# Plot 3: Equity Curves\nax3 = axes[2]\ntime_index = df_backtest.index\n\nax3.plot(time_index, results_A['equity_curve'], label=f'Option A ({best_model_name_A})', \n         color='blue', linewidth=2.5, alpha=0.8)\nax3.plot(time_index, results_B['equity_curve'], label=f'Option B ({best_model_name_B})', \n         color='green', linewidth=2.5, alpha=0.8)\nax3.plot(time_index, results_benchmark['equity_curve'], label='Benchmark: Rule-Based', \n         color='orange', linewidth=2.5, alpha=0.8)\n\nax3.axhline(y=10000, color='gray', linestyle='--', linewidth=1, alpha=0.5, label='Starting Capital')\n\nfor results, color, name in [\n    (results_A, 'blue', 'A'),\n    (results_B, 'green', 'B'),\n    (results_benchmark, 'orange', 'Bench')\n]:\n    final = results['final_capital']\n    ax3.text(time_index[-1], final, f'  {name}: ${final:.0f} (+{results[\"total_return\"]:.1f}%)',\n             fontsize=10, fontweight='bold', color=color, va='center')\n\nax3.set_title('Portfolio Equity Curves - A/B Comparison', fontsize=14, fontweight='bold')\nax3.set_xlabel('Time', fontsize=12)\nax3.set_ylabel('Portfolio Value (USD)', fontsize=12)\nax3.legend(loc='upper left', fontsize=10)\nax3.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('ab_test_comparison_fixed.png', dpi=150, bbox_inches='tight')\nprint(\"\\nVisualization saved as: ab_test_comparison_fixed.png\")\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"A/B TEST COMPLETE - FIXED VERSION\")\nprint(\"=\"*70)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}